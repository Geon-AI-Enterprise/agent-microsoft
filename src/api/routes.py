"""
API Routes - Twilio Integration

Adaptado para processar eventos JSON do Twilio Media Streams.
Inclui pr√©-processamento com WebRTC VAD (Leve e Eficiente).
"""

import asyncio
import base64
import json
import logging
import socket
import time
import audioop
import webrtcvad  # <--- A nova biblioteca leve
from contextlib import asynccontextmanager
from typing import List

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from supabase import create_client

from src.core.config import get_settings, AgentConfig
from src.services.voice_assistant import VoiceAssistantWorker
from src.services.client_manager import ClientManager

logger = logging.getLogger(__name__)
settings = get_settings()

# ==============================================================================
# DIAGN√ìSTICO DE STARTUP
# ==============================================================================
async def run_startup_diagnostics():
    logger.info("ü©∫ INICIANDO DIAGN√ìSTICO...")
    try:
        # Teste r√°pido do WebRTC VAD
        vad = webrtcvad.Vad(3)
        # Cria um frame de sil√™ncio de 20ms a 8000Hz (320 bytes)
        frame = b'\x00' * 320
        assert vad.is_speech(frame, 8000) is False
        logger.info(f"‚úÖ WebRTC VAD OK")
    except Exception as e:
        logger.error(f"‚ùå FALHA VAD: {e}")

    # ... (restante dos diagn√≥sticos de rede e supabase) ...
    # Pode manter o c√≥digo original de teste de rede e supabase aqui

# ==============================================================================
# INICIALIZA√á√ÉO E LIFESPAN (MANTIDOS IGUAIS)
# ==============================================================================
worker = None
worker_task = None

# ... (Manter c√≥digo de inicializa√ß√£o global e lifespan igual ao anterior) ...
# Vou resumir para focar na mudan√ßa principal, mas voc√™ deve manter o c√≥digo existente.

@asynccontextmanager
async def lifespan(app: FastAPI):
    await run_startup_diagnostics()
    yield
    if worker: worker.shutdown()

app = FastAPI(title="Azure VoiceLive Agent", lifespan=lifespan)

# ... (Endpoints HTTP /health e root mantidos iguais) ...
@app.get("/health")
async def health_check():
    return {"status": "ok", "env": settings.APP_ENV}

@app.get("/")
async def root():
    return {"message": "Twilio Media Stream Ready", "docs": "/docs"}

# ==============================================================================
# WEBSOCKET - TWILIO (COM WEBRTC VAD)
# ==============================================================================
@app.websocket("/ws/audio/{sip_number}")
async def audio_stream(websocket: WebSocket, sip_number: str):
    await websocket.accept()
    logger.info(f"üîå Conex√£o Twilio: {sip_number}")
    
    session_worker = None
    session_task = None
    stream_sid = None
    
    # --- CONFIGURA√á√ÉO VAD ---
    # Modo 3 √© o mais agressivo (filtra mais ru√≠do)
    vad = webrtcvad.Vad(3)
    
    # Twilio (G.711) = 8000Hz
    # WebRTC exige frames de 10, 20 ou 30ms.
    # 20ms a 8000Hz = 160 amostras.
    # Em PCM 16-bit (2 bytes/amostra), 160 * 2 = 320 bytes.
    FRAME_SIZE_BYTES = 320 
    SAMPLE_RATE = 8000
    
    # L√≥gica de Sil√™ncio
    VAD_TIMEOUT_MS = 1000 # 1 segundo de sil√™ncio fecha o turno
    
    try:
        # ... (L√≥gica de carregar config do cliente - Mantida igual) ...
        client_manager = ClientManager(settings.SUPABASE_URL, settings.SUPABASE_SERVICE_ROLE_KEY)
        client_config = client_manager.get_client_config(sip_number)
        if not client_config:
            await websocket.close(code=4000)
            return

        # ... (Callbacks send_audio e send_clear - Mantidos iguais) ...
        async def send_audio_to_twilio(audio_data: bytes):
            if not stream_sid: return
            try:
                payload = base64.b64encode(audio_data).decode('utf-8')
                await websocket.send_json({
                    "event": "media",
                    "streamSid": stream_sid,
                    "media": {"payload": payload}
                })
            except: pass

        async def send_clear_buffer():
            if not stream_sid: return
            try:
                await websocket.send_json({"event": "clear", "streamSid": stream_sid})
            except: pass

        # Inicializa Worker
        session_worker = VoiceAssistantWorker(
            agent_config=client_config,
            settings=settings,
            audio_output_handler=send_audio_to_twilio,
            interruption_handler=send_clear_buffer
        )
        session_task = asyncio.create_task(session_worker.connect_and_run())
        
        # --- BUFFERS ---
        pcm_buffer = bytearray()
        packet_queue: List[str] = []
        
        # Estado VAD
        last_speech_time = 0.0
        is_speaking = False
        
        while True:
            try:
                message = await websocket.receive_text()
                data = json.loads(message)
                event_type = data.get("event")

                if event_type == "media":
                    payload = data["media"]["payload"]
                    
                    if session_worker.connection:
                        # 1. Decodificar e Converter
                        chunk_ulaw = base64.b64decode(payload)
                        chunk_pcm = audioop.ulaw2lin(chunk_ulaw, 2)
                        
                        # 2. Bufferizar PCM para an√°lise
                        pcm_buffer.extend(chunk_pcm)
                        packet_queue.append(payload)
                        
                        # 3. Processar frames de tamanho exato (320 bytes = 20ms)
                        while len(pcm_buffer) >= FRAME_SIZE_BYTES:
                            frame = pcm_buffer[:FRAME_SIZE_BYTES]
                            pcm_buffer = pcm_buffer[FRAME_SIZE_BYTES:] # Remove do buffer
                            
                            # VAD Check (Retorna True/False instantaneamente)
                            if vad.is_speech(frame, SAMPLE_RATE):
                                last_speech_time = time.time()
                                if not is_speaking:
                                    is_speaking = True
                                    logger.info("üó£Ô∏è Voz detectada")
                        
                        # 4. Decis√£o de Envio
                        # Se falou nos √∫ltimos X ms, envia tudo que est√° na fila
                        current_time = time.time()
                        silence_duration = (current_time - last_speech_time) * 1000
                        
                        if silence_duration < VAD_TIMEOUT_MS:
                            # Estamos em um turno de fala ativo
                            while packet_queue:
                                p = packet_queue.pop(0)
                                await session_worker.connection.input_audio_buffer.append(audio=p)
                        else:
                            # Sil√™ncio prolongado
                            if is_speaking:
                                logger.info(f"üõë Sil√™ncio ({silence_duration:.0f}ms). Turno Fechado.")
                                # Limpa buffer do Azure para garantir que ele processe o que recebeu
                                await session_worker.connection.input_audio_buffer.commit()
                                is_speaking = False
                            
                            # Descarta o √°udio da fila (√© ru√≠do/sil√™ncio)
                            packet_queue.clear()

                elif event_type == "start":
                    stream_sid = data["start"]["streamSid"]
                elif event_type == "stop":
                    break
                    
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.error(f"‚ùå Erro loop: {e}")
                break

    except Exception as e:
        logger.critical(f"‚ùå Erro cr√≠tico: {e}")
    finally:
        if session_worker: session_worker.shutdown()
        if session_task: session_task.cancel()
        logger.info(f"‚úÖ Sess√£o finalizada: {sip_number}")